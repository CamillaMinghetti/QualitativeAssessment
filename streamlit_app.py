import streamlit as st
import pandas as pd
import os
import json
import datetime
import re
import base64
import streamlit.components.v1 as components
import gspread
from google.oauth2.service_account import Credentials

# Set page layout to wide for responsiveness
st.set_page_config(layout="wide")

# ----- Gestione delle Pagine -----
if "page" not in st.session_state:
    st.session_state.page = 1  # Pagina iniziale

def next_page():
    st.session_state.page += 1

def prev_page():
    st.session_state.page -= 1

# ----- Controllo per avviare il questionario -----
if "questionnaire_started" not in st.session_state:
    st.session_state.questionnaire_started = False

# ----- Pagina 1: Introduzione -----
if st.session_state.page == 1:
    st.title("Qualitative Performance Assessment of EndoDAC and Depth Pro Models")
    
    st.write(
        "*Colorectal cancer is one of the leading causes of death worldwide, "
        "and its early detection by colonoscopy is critical to improve the likelihood of success. "
        "However, two-dimensional visualization during colonoscopy can limit diagnostic accuracy, "
        "increasing the risk of undetected lesions. Depth estimation is therefore crucial to reconstruct a "
        "three-dimensional view of the bowel environment, improving diagnostic accuracy. "
        "However, obtaining accurate reference data (ground truth) in the clinical setting is particularly difficult "
        "due to the complexity of images and anatomical variability of patients. In this context, foundation AI models, "
        "pre-trained on huge amounts of data, could be a promising solution.*"
        "\n\n"
        "*To evaluate the effectiveness of AI models of depth estimation in endoscopy, it is crucial to involve clinicians directly, "
        "given the absence of an accurate ground truth with which to compare artificial intelligence predictions. "
        "For this reason, a questionnaire was developed for endoscopy specialists, with the aim of collecting opinions "
        "on the reliability of depth estimates generated by the analyzed models.*"
    )

    if st.button("Continue"):
        next_page()  # Navigate to the next page (Page 2)

# ----- Pagina 2: Spiegazione del Questionario -----
elif st.session_state.page == 2:
    st.title("Qualitative Performance Assessment of EndoDAC and Depth Pro Models")
    
    st.write(
        "The questionnaire consists of viewing several videos. In the center, a real colonoscopy video will be displayed, "
        "while on the left and right, depth maps generated by two different AI models will be shown. \n\n"
        "The depth maps generated by the two predictive models use a color gradient, "
        "where blue represents the deepest areas, transitioning through green and yellow for intermediate depths, "
        "and finally red indicating the shallowest areas."
    )

    # Add an image (e.g., explanatory image about the depth maps or the models)
    st.image("./frame_00379.png", caption="Example Depth Maps from AI Models", use_column_width=True)

    if st.button("Start Questionnaire"):
        next_page()  # Navigate to the next page (Page 3)

# ----- Pagina 3: Start Questionnaire -----
elif st.session_state.page == 3:
    # Page 3: Display the start button to begin the questionnaire
    st.title("Start Questionnaire")
    
    # Display the "Start Questionnaire" button to move to Page 4
    if st.button("Start Questionnaire"):
        next_page()  # Navigate to the next page (Page 4)

# ----- Pagina 4: Questionario -----
elif st.session_state.page == 4:
    st.header("Qualitative Performance Assessment of EndoDAC and Depth Pro Models")
    
    # Clinician Questions
    clinician = st.radio("Are you a clinician?", ["Yes", "No"])
    experience_level = None
    procedures_performed = None
    if clinician == "Yes":
        experience_level = st.radio("What is your experience level?", ["Resident", "Expert (at least 5000 procedures performed)"])
    
    # Name input
    name = st.text_input("Please enter your name")

    # Video Paths
    VIDEO_MAX_WIDTH = 640
    video_paths = [
        "./VideoColonoscopy3.mp4",
        "./VideoColonoscopy4.mp4",
        "./VideoColonoscopy5.mp4",
        "./VideoColonoscopy6.mp4",
        "./VideoColonoscopy7.mp4",
        "./VideoColonoscopy8.mp4",
        "./VideoColonoscopy9.mp4",
        "./VideoColonoscopy10.mp4",
        "./VideoColonoscopy11.mp4",
        "./VideoColonoscopy12.mp4",
    ]

    # Session State Initialization
    if "question_index" not in st.session_state:
        st.session_state["question_index"] = 0
    if "responses" not in st.session_state:
        st.session_state["responses"] = [None] * len(video_paths)

    if name:
        question_index = st.session_state["question_index"]
        st.subheader(f"Question {question_index + 1}")

        # Apply CSS to reduce space between question and video
        st.markdown("""
            <style>
                .question-container {
                    margin-bottom: 5px;
                }
                .video-container {
                    margin-top: 5px;
                }
            </style>
        """, unsafe_allow_html=True)

        # Video section
        video_path = video_paths[question_index]
        video_html = get_video_html(video_path, VIDEO_MAX_WIDTH)
        if video_html:
            components.html(video_html, height=int(VIDEO_MAX_WIDTH * 0.75), key=f"video_{question_index}")

        # Question section
        options = ["Left", "Right"]
        existing_response = st.session_state["responses"][question_index]
        default_index = options.index(existing_response) if existing_response in ["Left", "Right"] else 0

        response = st.radio(
             "Which of the two side videos (left or right) do you think best reflects reality in terms of accuracy in depth estimation?\nSelect an option:",
            options,
            key=f"question_{question_index}",
            index=default_index
        )

        if response in ["Left", "Right"]:
            st.session_state["responses"][question_index] = response
        else:
            st.session_state["responses"][question_index] = None

        col1, col2 = st.columns(2)
        with col1:
            if st.button("Previous") and question_index > 0:
                st.session_state["question_index"] -= 1
                st.rerun()
        with col2:
            if st.button("Next", disabled=(st.session_state["responses"][question_index] is None)) and question_index < len(video_paths) - 1:
                st.session_state["question_index"] += 1
                st.rerun()

        # Submission Block
        if question_index == len(video_paths) - 1 and st.button("Submit your answers", disabled=(st.session_state["responses"][question_index] is None)):
            responses_folder = "responses"
            if not os.path.exists(responses_folder):
                os.makedirs(responses_folder)

            safe_name = re.sub(r'[^\w\-_. ]', '_', name).strip()
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            file_name = f"{safe_name}_{timestamp}.json"
            file_path = os.path.join(responses_folder, file_name)

            new_data = {
                "Name": name,
                "Clinician": clinician,
                "Experience Level": experience_level if clinician == "Yes" else None,
            }
            for i in range(len(video_paths)):
                new_data[f"Question {i+1}"] = st.session_state["responses"][i] if st.session_state["responses"][i] else "No Response"

            try:
                with open(file_path, "w") as f:
                    json.dump(new_data, f, indent=4)
            except Exception as e:
                st.error(f"Error saving JSON file: {e}")

            # Google Sheets Setup
            try:
                scope = [
                    "https://www.googleapis.com/auth/spreadsheets",
                    "https://www.googleapis.com/auth/drive"
                ]
                creds_data = st.secrets["gcp_service_account"]
                creds = Credentials.from_service_account_info(creds_data, scopes=scope)
                client = gspread.authorize(creds)
                sheet = client.open("Responses_qualitative_assessment").sheet1

                row_data = [
                    name,
                    clinician,
                    experience_level if clinician == "Yes" else "",
                    procedures_performed if clinician == "Yes" else ""
                ]
                row_data.extend([st.session_state["responses"][i] if st.session_state["responses"][i] else "No Response" for i in range(len(video_paths))])

                sheet.append_row(row_data)
            except Exception as e:
                st.error(f"Errore nel salvataggio su Google Sheets: {e}")

            # Success message
            st.success("Your answers have been successfully saved!")

            # Show thank you message
            st.title("Thanks for taking part in the questionnaire!")

            # Stop the app after submission
            st.stop()



